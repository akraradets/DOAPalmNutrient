{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load Alexnet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy,copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the magic number\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "preprocess_augment = transforms.Compose([\n",
    "    transforms.Resize([256,256]),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize([256,256]),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1018\n"
     ]
    }
   ],
   "source": [
    "from myDataset import PalmNutriDataset\n",
    "ground_truth = 'dataset/gt.csv'\n",
    "full_train_dataset = PalmNutriDataset(ground_truth=ground_truth, img_dir='dataset', sample_set='n33')\n",
    "print(len(full_train_dataset))\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [800,218])\n",
    "train_dataset.dataset = copy(full_train_dataset)\n",
    "train_dataset.dataset.transform = preprocess_augment\n",
    "val_dataset.dataset.transform = preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "NUM_WORKERS=2\n",
    "train_dataloader = torch.utils.data.DataLoader(full_train_dataset, batch_size=BATCH_SIZE,shuffle=True , num_workers=NUM_WORKERS)\n",
    "val_dataloader   = torch.utils.data.DataLoader(val_dataset  , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)\n",
    "# test_dataloader  = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 0.0000\n",
      "Epoch time taken:  11.080638647079468\n",
      "Epoch 32/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0664 Acc: 0.0000\n",
      "Epoch time taken:  9.291091203689575\n",
      "val Loss: 0.0737 Acc: 0.0000\n",
      "Epoch time taken:  11.299354314804077\n",
      "Epoch 33/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0679 Acc: 0.0000\n",
      "Epoch time taken:  8.923615455627441\n",
      "val Loss: 0.0593 Acc: 0.0000\n",
      "Epoch time taken:  10.954325675964355\n",
      "Epoch 34/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0674 Acc: 0.0000\n",
      "Epoch time taken:  9.353230476379395\n",
      "val Loss: 0.0643 Acc: 0.0000\n",
      "Epoch time taken:  11.31627082824707\n",
      "Epoch 35/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0691 Acc: 0.0000\n",
      "Epoch time taken:  8.936419248580933\n",
      "val Loss: 0.0597 Acc: 0.0000\n",
      "Epoch time taken:  11.091858148574829\n",
      "Epoch 36/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0654 Acc: 0.0000\n",
      "Epoch time taken:  9.048686742782593\n",
      "val Loss: 0.0580 Acc: 0.0000\n",
      "Epoch time taken:  10.99838137626648\n",
      "Epoch 37/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0697 Acc: 0.0000\n",
      "Epoch time taken:  9.00818657875061\n",
      "val Loss: 0.0633 Acc: 0.0000\n",
      "Epoch time taken:  11.092392683029175\n",
      "Epoch 38/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.0000\n",
      "Epoch time taken:  9.224260568618774\n",
      "val Loss: 0.0835 Acc: 0.0000\n",
      "Epoch time taken:  11.219332218170166\n",
      "Epoch 39/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0652 Acc: 0.0000\n",
      "Epoch time taken:  9.066947937011719\n",
      "val Loss: 0.0634 Acc: 0.0000\n",
      "Epoch time taken:  11.143394470214844\n",
      "Epoch 40/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0639 Acc: 0.0000\n",
      "Epoch time taken:  9.226611375808716\n",
      "val Loss: 0.0612 Acc: 0.0000\n",
      "Epoch time taken:  11.249113082885742\n",
      "Epoch 41/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0643 Acc: 0.0000\n",
      "Epoch time taken:  9.070359468460083\n",
      "val Loss: 0.0633 Acc: 0.0000\n",
      "Epoch time taken:  11.193787574768066\n",
      "Epoch 42/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0663 Acc: 0.0000\n",
      "Epoch time taken:  8.889296293258667\n",
      "val Loss: 0.0658 Acc: 0.0000\n",
      "Epoch time taken:  10.982326030731201\n",
      "Epoch 43/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0655 Acc: 0.0000\n",
      "Epoch time taken:  9.232670545578003\n",
      "val Loss: 0.0555 Acc: 0.0000\n",
      "Epoch time taken:  11.486928462982178\n",
      "Epoch 44/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0623 Acc: 0.0000\n",
      "Epoch time taken:  9.223960638046265\n",
      "val Loss: 0.0617 Acc: 0.0000\n",
      "Epoch time taken:  11.216221570968628\n",
      "Epoch 45/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0642 Acc: 0.0000\n",
      "Epoch time taken:  9.042426824569702\n",
      "val Loss: 0.0779 Acc: 0.0000\n",
      "Epoch time taken:  11.098197937011719\n",
      "Epoch 46/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0626 Acc: 0.0000\n",
      "Epoch time taken:  9.019274711608887\n",
      "val Loss: 0.0669 Acc: 0.0000\n",
      "Epoch time taken:  11.066689014434814\n",
      "Epoch 47/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0625 Acc: 0.0000\n",
      "Epoch time taken:  8.905359745025635\n",
      "val Loss: 0.0963 Acc: 0.0000\n",
      "Epoch time taken:  10.854479312896729\n",
      "Epoch 48/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0658 Acc: 0.0000\n",
      "Epoch time taken:  8.970884084701538\n",
      "val Loss: 0.0617 Acc: 0.0000\n",
      "Epoch time taken:  11.108990669250488\n",
      "Epoch 49/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0638 Acc: 0.0000\n",
      "Epoch time taken:  9.19338583946228\n",
      "val Loss: 0.0631 Acc: 0.0000\n",
      "Epoch time taken:  11.177613973617554\n",
      "Epoch 50/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0629 Acc: 0.0000\n",
      "Epoch time taken:  8.902331590652466\n",
      "val Loss: 0.0705 Acc: 0.0000\n",
      "Epoch time taken:  10.95525050163269\n",
      "Epoch 51/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0605 Acc: 0.0000\n",
      "Epoch time taken:  9.080758571624756\n",
      "val Loss: 0.0555 Acc: 0.0000\n",
      "Epoch time taken:  11.299516916275024\n",
      "Epoch 52/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0589 Acc: 0.0000\n",
      "Epoch time taken:  9.313881397247314\n",
      "val Loss: 0.0664 Acc: 0.0000\n",
      "Epoch time taken:  11.317163944244385\n",
      "Epoch 53/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0597 Acc: 0.0000\n",
      "Epoch time taken:  9.038660764694214\n",
      "val Loss: 0.0882 Acc: 0.0000\n",
      "Epoch time taken:  11.010018110275269\n",
      "Epoch 54/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0606 Acc: 0.0000\n",
      "Epoch time taken:  8.981886625289917\n",
      "val Loss: 0.0651 Acc: 0.0000\n",
      "Epoch time taken:  11.12803339958191\n",
      "Epoch 55/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0616 Acc: 0.0000\n",
      "Epoch time taken:  9.003941774368286\n",
      "val Loss: 0.0523 Acc: 0.0000\n",
      "Epoch time taken:  11.060095310211182\n",
      "Epoch 56/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0601 Acc: 0.0000\n",
      "Epoch time taken:  9.171173572540283\n",
      "val Loss: 0.0582 Acc: 0.0000\n",
      "Epoch time taken:  11.223482370376587\n",
      "Epoch 57/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0580 Acc: 0.0000\n",
      "Epoch time taken:  8.95567798614502\n",
      "val Loss: 0.0654 Acc: 0.0000\n",
      "Epoch time taken:  10.914924383163452\n",
      "Epoch 58/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0596 Acc: 0.0000\n",
      "Epoch time taken:  8.916455507278442\n",
      "val Loss: 0.0501 Acc: 0.0000\n",
      "Epoch time taken:  10.891106128692627\n",
      "Epoch 59/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0614 Acc: 0.0000\n",
      "Epoch time taken:  9.016266107559204\n",
      "val Loss: 0.0592 Acc: 0.0000\n",
      "Epoch time taken:  10.96175217628479\n",
      "Epoch 60/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0599 Acc: 0.0000\n",
      "Epoch time taken:  9.182103157043457\n",
      "val Loss: 0.0507 Acc: 0.0000\n",
      "Epoch time taken:  11.181225776672363\n",
      "Epoch 61/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.0000\n",
      "Epoch time taken:  9.278310298919678\n",
      "val Loss: 0.0515 Acc: 0.0000\n",
      "Epoch time taken:  11.345025062561035\n",
      "Epoch 62/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0588 Acc: 0.0000\n",
      "Epoch time taken:  9.21588921546936\n",
      "val Loss: 0.0569 Acc: 0.0000\n",
      "Epoch time taken:  11.248819589614868\n",
      "Epoch 63/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0575 Acc: 0.0000\n",
      "Epoch time taken:  8.920521020889282\n",
      "val Loss: 0.0705 Acc: 0.0000\n",
      "Epoch time taken:  10.958788871765137\n",
      "Epoch 64/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0584 Acc: 0.0000\n",
      "Epoch time taken:  9.290897369384766\n",
      "val Loss: 0.0517 Acc: 0.0000\n",
      "Epoch time taken:  11.293109893798828\n",
      "Epoch 65/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0573 Acc: 0.0000\n",
      "Epoch time taken:  9.09562873840332\n",
      "val Loss: 0.0595 Acc: 0.0000\n",
      "Epoch time taken:  11.192614078521729\n",
      "Epoch 66/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0571 Acc: 0.0000\n",
      "Epoch time taken:  8.855567932128906\n",
      "val Loss: 0.0657 Acc: 0.0000\n",
      "Epoch time taken:  10.884053707122803\n",
      "Epoch 67/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0561 Acc: 0.0000\n",
      "Epoch time taken:  8.888246774673462\n",
      "val Loss: 0.0517 Acc: 0.0000\n",
      "Epoch time taken:  10.843015432357788\n",
      "Epoch 68/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0562 Acc: 0.0000\n",
      "Epoch time taken:  9.207104682922363\n",
      "val Loss: 0.0564 Acc: 0.0000\n",
      "Epoch time taken:  11.30903959274292\n",
      "Epoch 69/149:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.0570 Acc: 0.0000\n",
      "Epoch time taken:  9.02644157409668\n",
      "val Loss: 0.0559 Acc: 0.0000\n",
      "Epoch time taken:  11.151003122329712\n",
      "Epoch 70/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0523 Acc: 0.0000\n",
      "Epoch time taken:  9.07526159286499\n",
      "val Loss: 0.0474 Acc: 0.0000\n",
      "Epoch time taken:  11.02042007446289\n",
      "Epoch 71/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0508 Acc: 0.0000\n",
      "Epoch time taken:  9.263325214385986\n",
      "val Loss: 0.0478 Acc: 0.0000\n",
      "Epoch time taken:  11.309735536575317\n",
      "Epoch 72/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.0000\n",
      "Epoch time taken:  8.891512393951416\n",
      "val Loss: 0.0477 Acc: 0.0000\n",
      "Epoch time taken:  10.89380955696106\n",
      "Epoch 73/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.0000\n",
      "Epoch time taken:  8.951246500015259\n",
      "val Loss: 0.0471 Acc: 0.0000\n",
      "Epoch time taken:  10.933894395828247\n",
      "Epoch 74/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.0000\n",
      "Epoch time taken:  8.934913396835327\n",
      "val Loss: 0.0473 Acc: 0.0000\n",
      "Epoch time taken:  10.97105097770691\n",
      "Epoch 75/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0503 Acc: 0.0000\n",
      "Epoch time taken:  8.825763702392578\n",
      "val Loss: 0.0472 Acc: 0.0000\n",
      "Epoch time taken:  10.798308610916138\n",
      "Epoch 76/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0506 Acc: 0.0000\n",
      "Epoch time taken:  9.092623949050903\n",
      "val Loss: 0.0472 Acc: 0.0000\n",
      "Epoch time taken:  11.050800800323486\n",
      "Epoch 77/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0505 Acc: 0.0000\n",
      "Epoch time taken:  8.873610734939575\n",
      "val Loss: 0.0473 Acc: 0.0000\n",
      "Epoch time taken:  10.900343656539917\n",
      "Epoch 78/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.0000\n",
      "Epoch time taken:  9.226107358932495\n",
      "val Loss: 0.0471 Acc: 0.0000\n",
      "Epoch time taken:  11.270694494247437\n",
      "Epoch 79/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0501 Acc: 0.0000\n",
      "Epoch time taken:  9.064183235168457\n",
      "val Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  11.212839365005493\n",
      "Epoch 80/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.0000\n",
      "Epoch time taken:  8.621337652206421\n",
      "val Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  10.505581855773926\n",
      "Epoch 81/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0497 Acc: 0.0000\n",
      "Epoch time taken:  8.440402507781982\n",
      "val Loss: 0.0466 Acc: 0.0000\n",
      "Epoch time taken:  10.355188131332397\n",
      "Epoch 82/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0490 Acc: 0.0000\n",
      "Epoch time taken:  8.80890154838562\n",
      "val Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  10.712570190429688\n",
      "Epoch 83/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.0000\n",
      "Epoch time taken:  8.465955972671509\n",
      "val Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  10.341198444366455\n",
      "Epoch 84/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0489 Acc: 0.0000\n",
      "Epoch time taken:  8.390053510665894\n",
      "val Loss: 0.0471 Acc: 0.0000\n",
      "Epoch time taken:  10.27696943283081\n",
      "Epoch 85/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.0000\n",
      "Epoch time taken:  8.613183736801147\n",
      "val Loss: 0.0481 Acc: 0.0000\n",
      "Epoch time taken:  10.47667908668518\n",
      "Epoch 86/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0499 Acc: 0.0000\n",
      "Epoch time taken:  8.52621603012085\n",
      "val Loss: 0.0463 Acc: 0.0000\n",
      "Epoch time taken:  10.44503116607666\n",
      "Epoch 87/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0489 Acc: 0.0000\n",
      "Epoch time taken:  8.54275131225586\n",
      "val Loss: 0.0471 Acc: 0.0000\n",
      "Epoch time taken:  10.472140312194824\n",
      "Epoch 88/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0496 Acc: 0.0000\n",
      "Epoch time taken:  8.465995073318481\n",
      "val Loss: 0.0463 Acc: 0.0000\n",
      "Epoch time taken:  10.338966846466064\n",
      "Epoch 89/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.0000\n",
      "Epoch time taken:  8.423880815505981\n",
      "val Loss: 0.0464 Acc: 0.0000\n",
      "Epoch time taken:  10.329242706298828\n",
      "Epoch 90/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0491 Acc: 0.0000\n",
      "Epoch time taken:  8.479935884475708\n",
      "val Loss: 0.0466 Acc: 0.0000\n",
      "Epoch time taken:  10.386876106262207\n",
      "Epoch 91/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0488 Acc: 0.0000\n",
      "Epoch time taken:  8.453725337982178\n",
      "val Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  10.41478943824768\n",
      "Epoch 92/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0486 Acc: 0.0000\n",
      "Epoch time taken:  8.502151012420654\n",
      "val Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  10.413991451263428\n",
      "Epoch 93/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0483 Acc: 0.0000\n",
      "Epoch time taken:  8.455226182937622\n",
      "val Loss: 0.0462 Acc: 0.0000\n",
      "Epoch time taken:  10.307944536209106\n",
      "Epoch 94/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0489 Acc: 0.0000\n",
      "Epoch time taken:  8.628353357315063\n",
      "val Loss: 0.0459 Acc: 0.0000\n",
      "Epoch time taken:  10.530601739883423\n",
      "Epoch 95/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0484 Acc: 0.0000\n",
      "Epoch time taken:  8.46213150024414\n",
      "val Loss: 0.0461 Acc: 0.0000\n",
      "Epoch time taken:  10.362960577011108\n",
      "Epoch 96/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0483 Acc: 0.0000\n",
      "Epoch time taken:  8.5417959690094\n",
      "val Loss: 0.0461 Acc: 0.0000\n",
      "Epoch time taken:  10.438873767852783\n",
      "Epoch 97/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0488 Acc: 0.0000\n",
      "Epoch time taken:  8.535389184951782\n",
      "val Loss: 0.0460 Acc: 0.0000\n",
      "Epoch time taken:  10.41286301612854\n",
      "Epoch 98/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0480 Acc: 0.0000\n",
      "Epoch time taken:  8.524592638015747\n",
      "val Loss: 0.0473 Acc: 0.0000\n",
      "Epoch time taken:  10.3931245803833\n",
      "Epoch 99/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0481 Acc: 0.0000\n",
      "Epoch time taken:  8.363653659820557\n",
      "val Loss: 0.0454 Acc: 0.0000\n",
      "Epoch time taken:  10.204257249832153\n",
      "Epoch 100/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0485 Acc: 0.0000\n",
      "Epoch time taken:  8.438414812088013\n",
      "val Loss: 0.0460 Acc: 0.0000\n",
      "Epoch time taken:  10.336246013641357\n",
      "Epoch 101/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0492 Acc: 0.0000\n",
      "Epoch time taken:  8.279107570648193\n",
      "val Loss: 0.0460 Acc: 0.0000\n",
      "Epoch time taken:  10.163114786148071\n",
      "Epoch 102/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.0000\n",
      "Epoch time taken:  8.465358257293701\n",
      "val Loss: 0.0458 Acc: 0.0000\n",
      "Epoch time taken:  10.367881536483765\n",
      "Epoch 103/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0482 Acc: 0.0000\n",
      "Epoch time taken:  8.52930498123169\n",
      "val Loss: 0.0452 Acc: 0.0000\n",
      "Epoch time taken:  10.43270468711853\n",
      "Epoch 104/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0485 Acc: 0.0000\n",
      "Epoch time taken:  8.563538074493408\n",
      "val Loss: 0.0458 Acc: 0.0000\n",
      "Epoch time taken:  10.490084648132324\n",
      "Epoch 105/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.0000\n",
      "Epoch time taken:  8.489976406097412\n",
      "val Loss: 0.0456 Acc: 0.0000\n",
      "Epoch time taken:  10.38108205795288\n",
      "Epoch 106/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.0000\n",
      "Epoch time taken:  8.369091987609863\n",
      "val Loss: 0.0458 Acc: 0.0000\n",
      "Epoch time taken:  10.272355318069458\n",
      "Epoch 107/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0488 Acc: 0.0000\n",
      "Epoch time taken:  8.459552526473999\n",
      "val Loss: 0.0454 Acc: 0.0000\n",
      "Epoch time taken:  10.304195642471313\n",
      "Epoch 108/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0480 Acc: 0.0000\n",
      "Epoch time taken:  8.488006114959717\n",
      "val Loss: 0.0451 Acc: 0.0000\n",
      "Epoch time taken:  10.346934795379639\n",
      "Epoch 109/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0480 Acc: 0.0000\n",
      "Epoch time taken:  8.31375503540039\n",
      "val Loss: 0.0454 Acc: 0.0000\n",
      "Epoch time taken:  10.20759630203247\n",
      "Epoch 110/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.0000\n",
      "Epoch time taken:  8.549522399902344\n",
      "val Loss: 0.0465 Acc: 0.0000\n",
      "Epoch time taken:  10.466182231903076\n",
      "Epoch 111/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0481 Acc: 0.0000\n",
      "Epoch time taken:  8.535060167312622\n",
      "val Loss: 0.0451 Acc: 0.0000\n",
      "Epoch time taken:  10.40368366241455\n",
      "Epoch 112/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0481 Acc: 0.0000\n",
      "Epoch time taken:  8.599825382232666\n",
      "val Loss: 0.0450 Acc: 0.0000\n",
      "Epoch time taken:  10.491286754608154\n",
      "Epoch 113/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0465 Acc: 0.0000\n",
      "Epoch time taken:  8.605739831924438\n",
      "val Loss: 0.0449 Acc: 0.0000\n",
      "Epoch time taken:  10.49087119102478\n",
      "Epoch 114/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0482 Acc: 0.0000\n",
      "Epoch time taken:  8.571602821350098\n",
      "val Loss: 0.0452 Acc: 0.0000\n",
      "Epoch time taken:  10.428756952285767\n",
      "Epoch 115/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0474 Acc: 0.0000\n",
      "Epoch time taken:  8.46877384185791\n",
      "val Loss: 0.0449 Acc: 0.0000\n",
      "Epoch time taken:  10.36507797241211\n",
      "Epoch 116/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0473 Acc: 0.0000\n",
      "Epoch time taken:  8.411739110946655\n",
      "val Loss: 0.0450 Acc: 0.0000\n",
      "Epoch time taken:  10.292150974273682\n",
      "Epoch 117/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0480 Acc: 0.0000\n",
      "Epoch time taken:  8.375488996505737\n",
      "val Loss: 0.0460 Acc: 0.0000\n",
      "Epoch time taken:  10.29192042350769\n",
      "Epoch 118/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.0000\n",
      "Epoch time taken:  8.427557468414307\n",
      "val Loss: 0.0448 Acc: 0.0000\n",
      "Epoch time taken:  10.284671783447266\n",
      "Epoch 119/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  8.659855365753174\n",
      "val Loss: 0.0446 Acc: 0.0000\n",
      "Epoch time taken:  10.552916765213013\n",
      "Epoch 120/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.0000\n",
      "Epoch time taken:  8.6247079372406\n",
      "val Loss: 0.0457 Acc: 0.0000\n",
      "Epoch time taken:  10.503928184509277\n",
      "Epoch 121/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0478 Acc: 0.0000\n",
      "Epoch time taken:  8.378893852233887\n",
      "val Loss: 0.0444 Acc: 0.0000\n",
      "Epoch time taken:  10.286566972732544\n",
      "Epoch 122/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0475 Acc: 0.0000\n",
      "Epoch time taken:  8.539641380310059\n",
      "val Loss: 0.0447 Acc: 0.0000\n",
      "Epoch time taken:  10.42233681678772\n",
      "Epoch 123/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  8.403366804122925\n",
      "val Loss: 0.0447 Acc: 0.0000\n",
      "Epoch time taken:  10.299957275390625\n",
      "Epoch 124/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  8.425056219100952\n",
      "val Loss: 0.0449 Acc: 0.0000\n",
      "Epoch time taken:  10.276679992675781\n",
      "Epoch 125/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0464 Acc: 0.0000\n",
      "Epoch time taken:  8.560688734054565\n",
      "val Loss: 0.0456 Acc: 0.0000\n",
      "Epoch time taken:  10.480499982833862\n",
      "Epoch 126/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.42624545097351\n",
      "val Loss: 0.0446 Acc: 0.0000\n",
      "Epoch time taken:  10.296539068222046\n",
      "Epoch 127/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0468 Acc: 0.0000\n",
      "Epoch time taken:  8.527909994125366\n",
      "val Loss: 0.0441 Acc: 0.0000\n",
      "Epoch time taken:  10.408870697021484\n",
      "Epoch 128/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.59316897392273\n",
      "val Loss: 0.0441 Acc: 0.0000\n",
      "Epoch time taken:  10.462059259414673\n",
      "Epoch 129/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0464 Acc: 0.0000\n",
      "Epoch time taken:  8.58227014541626\n",
      "val Loss: 0.0447 Acc: 0.0000\n",
      "Epoch time taken:  10.46288251876831\n",
      "Epoch 130/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.360475778579712\n",
      "val Loss: 0.0449 Acc: 0.0000\n",
      "Epoch time taken:  10.245145320892334\n",
      "Epoch 131/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0473 Acc: 0.0000\n",
      "Epoch time taken:  8.458118200302124\n",
      "val Loss: 0.0444 Acc: 0.0000\n",
      "Epoch time taken:  10.347980499267578\n",
      "Epoch 132/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.421294212341309\n",
      "val Loss: 0.0464 Acc: 0.0000\n",
      "Epoch time taken:  10.307686567306519\n",
      "Epoch 133/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  8.445871114730835\n",
      "val Loss: 0.0456 Acc: 0.0000\n",
      "Epoch time taken:  10.323373794555664\n",
      "Epoch 134/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0468 Acc: 0.0000\n",
      "Epoch time taken:  8.540617942810059\n",
      "val Loss: 0.0443 Acc: 0.0000\n",
      "Epoch time taken:  10.447381734848022\n",
      "Epoch 135/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.611170291900635\n",
      "val Loss: 0.0438 Acc: 0.0000\n",
      "Epoch time taken:  10.505529642105103\n",
      "Epoch 136/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.0000\n",
      "Epoch time taken:  8.516128063201904\n",
      "val Loss: 0.0446 Acc: 0.0000\n",
      "Epoch time taken:  10.467487096786499\n",
      "Epoch 137/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0461 Acc: 0.0000\n",
      "Epoch time taken:  8.44815969467163\n",
      "val Loss: 0.0437 Acc: 0.0000\n",
      "Epoch time taken:  10.377470970153809\n",
      "Epoch 138/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0461 Acc: 0.0000\n",
      "Epoch time taken:  8.570042133331299\n",
      "val Loss: 0.0437 Acc: 0.0000\n",
      "Epoch time taken:  10.430376052856445\n",
      "Epoch 139/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0466 Acc: 0.0000\n",
      "Epoch time taken:  8.430602312088013\n",
      "val Loss: 0.0435 Acc: 0.0000\n",
      "Epoch time taken:  10.32728123664856\n",
      "Epoch 140/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0464 Acc: 0.0000\n",
      "Epoch time taken:  8.510998249053955\n",
      "val Loss: 0.0436 Acc: 0.0000\n",
      "Epoch time taken:  10.396747827529907\n",
      "Epoch 141/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.0000\n",
      "Epoch time taken:  8.44874906539917\n",
      "val Loss: 0.0435 Acc: 0.0000\n",
      "Epoch time taken:  10.326241254806519\n",
      "Epoch 142/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.0000\n",
      "Epoch time taken:  8.547402143478394\n",
      "val Loss: 0.0446 Acc: 0.0000\n",
      "Epoch time taken:  10.45085859298706\n",
      "Epoch 143/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  8.336498975753784\n",
      "val Loss: 0.0433 Acc: 0.0000\n",
      "Epoch time taken:  10.22942590713501\n",
      "Epoch 144/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0457 Acc: 0.0000\n",
      "Epoch time taken:  8.656209945678711\n",
      "val Loss: 0.0436 Acc: 0.0000\n",
      "Epoch time taken:  10.547423839569092\n",
      "Epoch 145/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0467 Acc: 0.0000\n",
      "Epoch time taken:  8.423516273498535\n",
      "val Loss: 0.0433 Acc: 0.0000\n",
      "Epoch time taken:  10.297061204910278\n",
      "Epoch 146/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0469 Acc: 0.0000\n",
      "Epoch time taken:  8.611316204071045\n",
      "val Loss: 0.0450 Acc: 0.0000\n",
      "Epoch time taken:  10.497098684310913\n",
      "Epoch 147/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.0000\n",
      "Epoch time taken:  8.48259425163269\n",
      "val Loss: 0.0434 Acc: 0.0000\n",
      "Epoch time taken:  10.373343706130981\n",
      "Epoch 148/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 0.0000\n",
      "Epoch time taken:  8.608506441116333\n",
      "val Loss: 0.0435 Acc: 0.0000\n",
      "Epoch time taken:  10.518977880477905\n",
      "Epoch 149/149:LR: 0.001\n",
      "----------\n",
      "train Loss: 0.0462 Acc: 0.0000\n",
      "Epoch time taken:  8.482401609420776\n",
      "val Loss: 0.0470 Acc: 0.0000\n",
      "Epoch time taken:  10.352102279663086\n",
      "Training complete in 28m 38s\n",
      "Best val Acc: 0.043266\n"
     ]
    }
   ],
   "source": [
    "from trainer import trainer\n",
    "dataloaders = {'train': train_dataloader,'val':val_dataloader}\n",
    "# Set device to GPU or CPU\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = models.alexnet()\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096,out_features=1)\n",
    "# Optimizer and loss function\n",
    "criterion = nn.MSELoss()\n",
    "params_to_update = model.parameters()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = optim.Adam(params_to_update, lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min')\n",
    "t = trainer(device,criterion, optimizer,scheduler)\n",
    "model = t.train(model, dataloaders, num_epochs=150, weights_name='alex_sgd_0.01')\n",
    "# t.test(model,test_dataloader)"
   ]
  }
 ]
}