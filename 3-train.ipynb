{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Load Alexnet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the magic number\n",
    "mean, std = (0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "preprocess_augment = transforms.Compose([\n",
    "    transforms.Resize([256,256]),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize([256,256]),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myDataset import PalmNutriDataset\n",
    "ground_truth = 'dataset/gt.csv'\n",
    "full_train_dataset = PalmNutriDataset(ground_truth=ground_truth, img_dir='dataset', sample_set='n17')\n",
    "full_train_dataset.transform = preprocess\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(full_train_dataset, [40000, 10000])\n",
    "# train_dataset.dataset = copy(full_train_dataset)\n",
    "# train_dataset.dataset.transform = preprocess_augment\n",
    "# val_dataset.dataset.transform = preprocess\n",
    "# test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=4\n",
    "NUM_WORKERS=1\n",
    "train_dataloader = torch.utils.data.DataLoader(full_train_dataset, batch_size=BATCH_SIZE,shuffle=True , num_workers=NUM_WORKERS)\n",
    "# val_dataloader   = torch.utils.data.DataLoader(val_dataset  , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)\n",
    "# test_dataloader  = torch.utils.data.DataLoader(test_dataset , batch_size=BATCH_SIZE,shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:1\n",
      "Epoch 0/59:LR: 0.01\n",
      "----------\n",
      "train Loss: 0.5073 Acc: 0.0000\n",
      "Epoch time taken:  16.03031301498413\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'val'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a13ef61cf61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'resnet18_adam_0.01'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/RTML/DOAPalmNutrient/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, dataloaders, num_epochs, weights_name, is_inception)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m                     \u001b[0;31m# for process anything, device and dataset must put in the same place.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0;31m# If the model is in GPU, input and output must set to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val'"
     ]
    }
   ],
   "source": [
    "from trainer import trainer\n",
    "dataloaders = {'train': train_dataloader}\n",
    "# Set device to GPU or CPU\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model = models.alexnet()\n",
    "model.classifier[6] = torch.nn.Linear(in_features=4096,out_features=1)\n",
    "# Optimizer and loss function\n",
    "criterion = nn.MSELoss()\n",
    "params_to_update = model.parameters()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = optim.Adam(params_to_update, lr=0.01)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min')\n",
    "t = trainer(device,criterion, optimizer,scheduler)\n",
    "model = t.train(model, dataloaders, num_epochs=60, weights_name='resnet18_adam_0.01')\n",
    "t.test(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'image': tensor([[[[-2.1577, -2.1577, -2.1577,  ..., -2.0801, -2.0995, -2.0995],\n          [-2.1577, -2.1577, -2.1771,  ..., -2.0995, -2.0995, -2.0801],\n          [-2.1577, -2.1577, -2.1771,  ..., -2.1383, -2.1189, -2.0995],\n          ...,\n          [-1.3435, -1.3241, -1.3047,  ..., -1.6537, -1.6343, -1.6537],\n          [-1.3629, -1.3241, -1.3241,  ..., -1.6731, -1.6343, -1.6149],\n          [-1.3629, -1.3047, -1.2660,  ..., -1.6924, -1.6343, -1.6149]],\n\n         [[-2.1429, -2.1429, -2.1429,  ..., -2.0446, -2.0446, -2.0643],\n          [-2.1429, -2.1429, -2.1626,  ..., -2.0643, -2.0643, -2.0446],\n          [-2.1429, -2.1429, -2.1429,  ..., -2.0643, -2.0643, -2.0446],\n          ...,\n          [-0.9039, -0.8646, -0.8449,  ..., -1.2972, -1.2972, -1.2972],\n          [-0.9039, -0.8646, -0.8646,  ..., -1.2776, -1.2776, -1.2579],\n          [-0.9039, -0.8449, -0.8056,  ..., -1.3169, -1.2579, -1.2382]],\n\n         [[-1.9287, -1.9482, -1.9482,  ..., -1.8117, -1.8312, -1.8312],\n          [-1.9287, -1.9482, -1.9678,  ..., -1.8312, -1.8312, -1.8117],\n          [-1.9482, -1.9482, -1.9678,  ..., -1.8507, -1.8702, -1.8507],\n          ...,\n          [-1.4410, -1.4215, -1.4020,  ..., -1.6166, -1.6361, -1.6751],\n          [-1.4410, -1.4215, -1.4020,  ..., -1.6361, -1.6556, -1.6556],\n          [-1.4215, -1.3825, -1.3434,  ..., -1.6946, -1.6751, -1.6751]]],\n\n\n        [[[-1.5374, -1.3629, -1.1497,  ..., -2.1383, -2.1189, -2.1189],\n          [-1.4986, -1.2854, -1.1303,  ..., -2.1383, -2.1383, -2.1383],\n          [-1.3823, -1.1884, -1.0527,  ..., -2.1383, -2.1383, -2.1383],\n          ...,\n          [-2.2740, -2.2740, -2.2934,  ..., -1.4598, -1.4598, -1.4598],\n          [-2.2740, -2.2934, -2.3128,  ..., -1.4986, -1.4598, -1.4792],\n          [-2.2740, -2.2740, -2.2934,  ..., -1.5374, -1.4986, -1.4598]],\n\n         [[-1.2382, -1.0612, -0.8056,  ..., -2.1233, -2.1036, -2.1036],\n          [-1.2186, -0.9826, -0.8056,  ..., -2.1233, -2.1233, -2.1233],\n          [-1.1006, -0.8646, -0.7269,  ..., -2.1036, -2.1233, -2.1233],\n          ...,\n          [-2.2609, -2.2609, -2.2609,  ..., -1.0416, -1.0416, -1.0416],\n          [-2.2609, -2.2806, -2.3003,  ..., -1.0612, -1.0416, -1.0612],\n          [-2.2609, -2.2609, -2.2806,  ..., -1.0809, -1.0809, -1.0416]],\n\n         [[-1.5580, -1.3825, -1.1483,  ..., -1.9287, -1.9092, -1.9092],\n          [-1.5385, -1.3239, -1.2069,  ..., -1.9287, -1.9287, -1.9287],\n          [-1.4020, -1.2264, -1.1288,  ..., -1.9287, -1.9287, -1.9287],\n          ...,\n          [-2.1043, -2.1434, -2.1434,  ..., -2.0068, -1.9873, -2.0458],\n          [-2.1043, -2.1238, -2.1434,  ..., -2.0458, -1.9873, -2.0068],\n          [-2.0848, -2.1043, -2.1238,  ..., -2.1434, -2.1238, -2.0653]]],\n\n\n        [[[-2.0995, -2.0995, -2.0995,  ..., -1.2854, -1.3435, -1.6343],\n          [-2.0995, -2.1189, -2.1189,  ..., -1.3047, -1.4017, -1.6149],\n          [-2.0995, -2.0995, -2.0995,  ..., -1.3047, -1.3823, -1.6537],\n          ...,\n          [-0.4906, -0.3743, -0.2967,  ..., -1.2466, -1.3823, -1.3047],\n          [-0.5487, -0.3549, -0.3936,  ..., -1.2272, -1.3823, -1.4017],\n          [-0.5487, -0.3549, -0.3161,  ..., -1.2660, -1.4211, -1.4598]],\n\n         [[-2.0839, -2.0839, -2.0839,  ..., -1.1792, -1.2579, -1.5529],\n          [-2.0839, -2.1036, -2.1036,  ..., -1.1989, -1.2972, -1.5136],\n          [-2.0839, -2.0839, -2.0839,  ..., -1.1792, -1.2579, -1.5529],\n          ...,\n          [-0.0386,  0.0794,  0.1384,  ..., -1.1596, -1.3169, -1.2579],\n          [-0.0189,  0.1581,  0.0794,  ..., -1.1596, -1.3169, -1.3562],\n          [ 0.0598,  0.2368,  0.2368,  ..., -1.1792, -1.3366, -1.3956]],\n\n         [[-1.8897, -1.8897, -1.8897,  ..., -1.3825, -1.4410, -1.6946],\n          [-1.8897, -1.9092, -1.9092,  ..., -1.4215, -1.4800, -1.6751],\n          [-1.8897, -1.8897, -1.8897,  ..., -1.4020, -1.4605, -1.6946],\n          ...,\n          [ 0.0808,  0.2174,  0.3345,  ..., -1.5190, -1.6166, -1.4215],\n          [ 0.1003,  0.2954,  0.2564,  ..., -1.4605, -1.5580, -1.5190],\n          [ 0.1394,  0.3149,  0.3540,  ..., -1.5190, -1.5776, -1.5580]]],\n\n\n        [[[-2.1771, -2.1577, -2.1577,  ..., -1.3241, -1.3435, -1.7312],\n          [-2.1577, -2.1383, -2.1383,  ..., -1.2466, -1.2466, -1.5180],\n          [-2.1383, -2.1383, -2.1383,  ..., -1.3241, -1.3435, -1.5374],\n          ...,\n          [-1.9057, -1.8863, -1.9251,  ..., -1.8281, -1.8281, -1.8281],\n          [-1.8669, -1.8863, -1.9057,  ..., -1.8281, -1.8281, -1.8475],\n          [-1.8669, -1.8863, -1.9251,  ..., -1.8281, -1.8475, -1.8475]],\n\n         [[-2.1233, -2.1233, -2.1429,  ..., -1.0416, -1.1006, -1.5332],\n          [-2.1233, -2.1233, -2.1233,  ..., -0.9629, -0.9826, -1.2972],\n          [-2.1233, -2.1233, -2.1233,  ..., -1.0022, -1.0612, -1.3366],\n          ...,\n          [-1.6512, -1.6119, -1.6512,  ..., -1.4742, -1.4742, -1.4939],\n          [-1.6119, -1.6119, -1.6316,  ..., -1.4742, -1.4742, -1.5136],\n          [-1.6316, -1.6316, -1.6512,  ..., -1.4939, -1.5136, -1.5136]],\n\n         [[-1.9482, -1.9482, -1.9482,  ..., -1.7727, -1.7141, -1.8702],\n          [-1.9482, -1.9287, -1.9287,  ..., -1.7727, -1.6946, -1.7727],\n          [-1.9287, -1.9287, -1.9287,  ..., -1.7727, -1.7141, -1.7531],\n          ...,\n          [-1.9287, -1.9482, -2.0068,  ..., -2.1043, -2.0848, -2.0458],\n          [-1.9287, -1.9678, -2.0068,  ..., -2.1238, -2.1043, -2.0653],\n          [-1.9482, -1.9678, -2.0068,  ..., -2.0653, -2.0653, -2.0263]]]]), 'label': tensor([2.5580, 2.0760, 2.6110, 1.9730], dtype=torch.float64)}\n"
     ]
    }
   ],
   "source": [
    "for i in train_dataloader:\n",
    "    print(i)\n",
    "    break"
   ]
  }
 ]
}